{
  "hash": "d3fe96466d6dc6c33d44fb92306b5693",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nformat: gfm\nlayout: single_md.pug\ntags: [\"posts\"]\ntitle: \"The Greedy Permutation\"\nauthor: \"Matt Piekenbrock\"\ndate: '2024-04-29'\nslug: landmark\ninclude_toc: true\ncategories: [\"computer science\", \"algorithms\", \"math\"]\ndraft: true\neditor:\n  rendor-on-save: true\nexecute:\n  echo: false\n  eval: true\n  freeze: auto\n  cache: true\nbibliography: ../references.bib\ncitations-hover: true\njupyter: blog\n---\n\n\n\nThere are many applications where one seeks to find a small yet representative subset of the data. Typically, we want to solve a problem $\\mathcal{P}$ with respect to data $X$, but we can't---*the data are simply too large*---so we must work with a subset $S \\subset X$ instead and *hope it suffices*.\n\nSometimes, this works. Sometimes, though, the solutions $\\mathcal{P}(S)$ deviate dramatically from the real problem $\\mathcal{P}(X)$. Ideally, we want a subset $S \\subset X$ small enough to be *feasibly computable* on $\\mathcal{P}$, but also representative enough such that the solution $\\mathcal{P}(S)$ *approximates* $\\mathcal{P}(X)$ under the appropriate notion, e.g. a $(1 \\pm \\epsilon)$ scheme:\n\n$$ (1 - \\epsilon) \\mathcal{P}(S) \\leq \\mathcal{P}(X) \\leq (1 + \\epsilon) \\mathcal{P}(S)$$\n\nOf course, the exact definitions of \"problem\" and \"feasibly\" and \"approximate\" vary, but a general term for subsets which **provably** achieve such approximations guarantees on their associated problems of interest are called [coresets](https://en.wikipedia.org/wiki/Coreset).\n\nCoresets they are *everywhere*: whether for vector quantization, low rank matrix approximation, or surface simplification, coresets have proven ubiquitous in scientific computing.\n\n<!-- pop up in a variety of computational, geometric, or learning settings. -->\n\n<!-- Indeed, the [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)---a cornerstone of deep learning---is a type of coreset. -->\n\n<!-- to computational problems like basic vector summation and to learning problems, like linear regression or principle component analysis.  -->\n\n<!-- it is slow and often ineffective to compute the full gradient each iteration of training, so we choose to approximate with \"batches.\"  -->\n\n<!-- https://sarielhp.org/p/15/greedy_permutation/permutation.pdf -->\n\n## One coreset to rule them all\n\nFascinating though they are, coreset theory can be quite complicated---most coresets are difficult to analyse, difficult to implement, and/or intrinsically problem-specific.\n\nExcept one. <!-- For example, in the diameter problem, random uniform sampling is not likely to give a good approximation error. -->\n\nThere is one particular coreset construction that is easy to construct, easy to analyze, and easy to implement. Moreover, it seems to have an unending number of applications, having been re-discovered time and time again: the **greedy permutation** (a.k.a the [farthest-first traversal](https://en.wikipedia.org/wiki/Farthest-first_traversal)). <!-- ubiquitous in computational geometry --> <!-- Greedy permutations are effective permutations of an input set that keep points as far apart as possible while minimizing the maximum distance from any point to the sample. --> The idea of the greedy permutation is to construct a permutation $P$ of a set $X$ that keeps successive points as far apart as possible, i.e. minimizing the maximum distance to previously encountered points. Here's a picture demonstrating the process:\n\n![Picture from *Approximate Greedy Clustering and Distance Selection for Graph Metrics*, by Eppstein et al](fft.png)\n\nTo clarify this construction, let $(X, d_X)$ denote a metric space of size $\\lvert X \\rvert = n$, and $P = (p_0, p_1, \\dots, p_{n-1})$ a sequence of points from $X$. The sequence $P$ is called a <u>*greedy permutation*</u> if, for all $i \\in [n]$, we have:\n\n$$d_X(p_i, P_i) = \\max_{p \\in P} d_X(p, P_i), \\quad P_i = \\{\\, p_0, \\dots, p_{i-1}\\,\\}$$\n\nwhere $d_X(x, S)$ represents the minimum distance between $x \\in X$ to any point in the set $S$. The first point $p_0$ is called the *seed* of the sequence $P$, and $P_i$ is called the *i-th* *prefix* of $P$.\n\nGreedy permutations are easy to construct: given a seed point $p_0$ and thus initial sequence $P = (p_0)$, choose the next point $p_1$ *greedily* by minimizing $d_X(p_0, P_1)$. Repeating this $k$-times constructs a subset $S \\subset X$ of size $\\lvert S \\rvert = k$ that in many ways approximates the set $X$; when $k = n$, the resulting sequence is a *permutation* of $X$.\n\n## Properties: it has all of them.\n\nAside form the fact that its representation is extremely simple---just a permutation of the set $X$---the greedy permutation comes equipped with a variety of 'nice' coverage and separation properties. To $$B(x, r) \\triangleq \\{ \\, x' \\in X : d_X(x, x') \\leq r \\, \\}$$\n\nOne of the principal interests in the greedy permutation is that it approximates the $k$-center clustering problem at all resolutions. Specifically, the $k$-prefix given by the first $k$ vertices of the permutations provides a $2$-approximation to the $k$-center clustering problem, for all $k \\in \\{ \\, 2, \\dots, n \\, \\}$.\n\n<!-- Assume we've constructed a greedy permutation $P$ of $X$. What are its properties, what problems can it approximate, and how does it relate to coresets? First, let's define a _ball_: -->\n\n<!-- Naive computation of the $k$-th prefix of the greedy permutation takes $O(nk)$ time, though  -->\n\n<!-- : given some problem $\\mathcal{P}$ defined on some data $X$, a _coreset_ $S$ is a proxy for the full data set satsifying the property that same algorithm can be run on the coreset as the full data set, and the result on the coreset approximates that on the full data set. -->\n\n<!-- Indeed, the cornerstone of [SGD](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) i -->\n\n<!-- a geometrically-oriented perspective on sampling is to choose a subset that preserves, in some sense, the *shape* of the underlying data. This goal is a bit lofty: we need precisely define both \"shape\" is, and how can we preserve it. -->\n\n<!-- The idea is as follows. Suppose we have some data $X$ equipped ia metric \\$d_X : X \\\\times X \\\\to \\\\mathbb{R}*+\\$ (i.e. a metric space \\$(X, d\\_*X)\\$) and some primitive operation $T : X \\to \\dots$ which computes some quantity of interest $\\dots.$ -->\n\n<!-- We would like to produce a subset $S \\subseteq X$ of $X$ such that the -->\n\n\n```{=html}\n<!-- <https://sarielhp.org/p/04/survey/survey.pdf>\n\n<https://en.wikipedia.org/wiki/Coreset> -->\n```\n\n```{=html}\n<!-- In machine learning, this challenge often manifests in tasks where pairwise distance computations are necessary, such as clustering, classification, anomaly detection.\n\nIn many computational geometry and computer graphics applications, one often wants to compare detailed meshes identifiable point on an object that corresponds to matching points on similar objects.\n\n$S \\subseteq X$\n\n$X$ -->\n```\n\n\n<!-- The metric k-center problem is a combinatorial optimization problem studied in theoretical computer science. Given n cities with specified distances, one wants to build k warehouses in different cities and minimize the maximum distance of a city to a warehouse. In graph theory, this means finding a set of k vertices for which the largest distance of any point to its closest vertex in the k-set is minimum. The vertices must be in a metric space, providing a complete graph that satisfies the triangle inequality. -->\n\n<!-- k-center for any metric space (X , dX ). Given a dataset S ⊆ X , the goal is to quickly find a set of centers T ⊆ X with the constraint \\|T\\| = k. The objective is that maxa∈§ dX (a, T) is minimized over all such sets T. Here we extend the definition of a distance function to sets by dX (a, T) = minb∈T dX (a, b). -->\n\n\n\n::: {style=\"display: flex; justify-content: center; align-items: center;\"}\n<iframe src=\"k_slider/index.html\" width=\"400px;\" height=\"450px;\" sandbox=\"allow-same-origin allow-scripts allow-forms\" style=\"overflow-y: hidden !important; text-overflow: hidden;\" scrolling=\"no\">\n\n</iframe>\n:::\n\n## Multiscale decomposition & quantization\n\nTo illustrate the broad utility of the greedy permutation, consider the classical *vector quantization* problem.\n\nTo see why this can be used for vector quantization, consider the problem of (lossily) compressing an $n \\times m$ grayscale image $I$. As a grayscale image, its intensity values can take any of the 256 values representable by an unsigned 8-bit integer. Let's assume a simple Huffman encoding scheme, wherein the goal is simply to produce a smaller image by replacing all $nm$ intensity values with a 'codeword' of a smaller length, the idea being that more frequently occurring pixels map to smaller codewords, while rarely occurring codewords necessarily take up more bits.\n\nFor example, in the parrot picture below\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport imageio\nparrot_mat = imageio.imread(\"/Users/mpiekenbrock/peekxc.github.io/content/posts/landmark/parrots/parrot.jpeg\")\nparrot_mat = parrot_mat[:,:,0]\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/0l/b3dbb2_d2bb4y3wbbfk0wt_80000gn/T/ipykernel_65069/3392017110.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  parrot_mat = imageio.imread(\"/Users/mpiekenbrock/peekxc.github.io/content/posts/landmark/parrots/parrot.jpeg\")\n```\n:::\n:::\n\n\nThis is a $316 \\times 474$ pixel image, each pixel value representing an unsigned 8-bit integer. Thus, the uncompressed storage size of this image ought to be \\~146 KB.\n\n$$ 316 \\times 464 \\times 8 = $$\n\nUnder the (lossless) huffman coding scheme, we get a symbol table that looks as follows:\n\n::: {.cell execution_count=5}\n\n::: {.cell-output .cell-output-stdout}\n```\nBits Code              Value Symbol\n   7 0000000               0 np.uint8(97)\n   7 0000001               1 np.uint8(219)\n   9 000001000             8 np.uint8(145)\n   9 000001001             9 np.uint8(151)\n   9 000001010            10 np.uint8(155)\n   9 000001011            11 np.uint8(154)\n   7 0000011               3 np.uint8(108)\n   7 0000100               4 np.uint8(75)\n   7 0000101               5 np.uint8(86)\n   7 0000110               6 np.uint8(217)\n   7 0000111               7 np.uint8(220)\n   7 0001000               8 np.uint8(90)\n   7 0001001               9 np.uint8(64)\n   9 000101000            40 np.uint8(156)\n  11 00010100100         164 np.uint8(14)\n  12 000101001010        330 np.uint8(243)\n  13 0001010010110       662 np.uint8(245)\n  14 00010100101110     1326 np.uint8(248)\n  14 00010100101111     1327 np.uint8(250)\n  11 00010100110         166 np.uint8(6)\n  11 00010100111         167 np.uint8(12)\n   8 00010101             21 np.uint8(29)\n   7 0001011              11 np.uint8(60)\n   6 000110                6 np.uint8(92)\n   7 0001110              14 np.uint8(71)\n   7 0001111              15 np.uint8(93)\n   6 001000                8 np.uint8(51)\n   7 0010010              18 np.uint8(85)\n   8 00100110             38 np.uint8(182)\n   9 001001110            78 np.uint8(126)\n   9 001001111            79 np.uint8(158)\n   7 0010100              20 np.uint8(77)\n   7 0010101              21 np.uint8(80)\n   9 001011000            88 np.uint8(150)\n   9 001011001            89 np.uint8(128)\n   8 00101101             45 np.uint8(184)\n   7 0010111              23 np.uint8(83)\n   7 0011000              24 np.uint8(78)\n   8 00110010             50 np.uint8(183)\n   8 00110011             51 np.uint8(124)\n   7 0011010              26 np.uint8(87)\n   7 0011011              27 np.uint8(63)\n   8 00111000             56 np.uint8(226)\n   8 00111001             57 np.uint8(225)\n   7 0011101              29 np.uint8(89)\n   7 0011110              30 np.uint8(66)\n   7 0011111              31 np.uint8(65)\n  10 0100000000          256 np.uint8(24)\n  11 01000000010         514 np.uint8(17)\n  11 01000000011         515 np.uint8(10)\n   9 010000001           129 np.uint8(157)\n   8 01000001             65 np.uint8(34)\n   7 0100001              33 np.uint8(72)\n   7 0100010              34 np.uint8(114)\n   7 0100011              35 np.uint8(56)\n   7 0100100              36 np.uint8(104)\n   7 0100101              37 np.uint8(67)\n   9 010011000           152 np.uint8(162)\n  11 01001100100         612 np.uint8(13)\n  11 01001100101         613 np.uint8(20)\n  10 0100110011          307 np.uint8(241)\n   8 01001101             77 np.uint8(224)\n   7 0100111              39 np.uint8(116)\n   6 010100               20 np.uint8(101)\n   7 0101010              42 np.uint8(69)\n   8 01010110             86 np.uint8(35)\n   9 010101110           174 np.uint8(161)\n   9 010101111           175 np.uint8(160)\n   6 010110               22 np.uint8(102)\n   7 0101110              46 np.uint8(70)\n   7 0101111              47 np.uint8(57)\n   7 0110000              48 np.uint8(84)\n   8 01100010             98 np.uint8(187)\n   8 01100011             99 np.uint8(30)\n   8 01100100            100 np.uint8(186)\n  11 01100101000         808 np.uint8(9)\n  11 01100101001         809 np.uint8(11)\n  11 01100101010         810 np.uint8(19)\n  11 01100101011         811 np.uint8(15)\n   9 011001011           203 np.uint8(127)\n   7 0110011              51 np.uint8(81)\n   8 01101000            104 np.uint8(32)\n   8 01101001            105 np.uint8(188)\n   8 01101010            106 np.uint8(238)\n   8 01101011            107 np.uint8(185)\n   7 0110110              54 np.uint8(62)\n   8 01101110            110 np.uint8(190)\n   9 011011110           222 np.uint8(166)\n  10 0110111110          446 np.uint8(25)\n  11 01101111110         894 np.uint8(18)\n  14 01101111111000     7160 np.uint8(251)\n  14 01101111111001     7161 np.uint8(255)\n  14 01101111111010     7162 np.uint8(246)\n  14 01101111111011     7163 np.uint8(249)\n  12 011011111111       1791 np.uint8(4)\n   7 0111000              56 np.uint8(88)\n   8 01110010            114 np.uint8(189)\n   8 01110011            115 np.uint8(39)\n   7 0111010              58 np.uint8(73)\n   7 0111011              59 np.uint8(74)\n   7 0111100              60 np.uint8(61)\n   8 01111010            122 np.uint8(33)\n   9 011110110           246 np.uint8(163)\n   9 011110111           247 np.uint8(165)\n   7 0111110              62 np.uint8(106)\n   7 0111111              63 np.uint8(58)\n   6 100000               32 np.uint8(95)\n   7 1000010              66 np.uint8(59)\n   7 1000011              67 np.uint8(91)\n   7 1000100              68 np.uint8(113)\n   7 1000101              69 np.uint8(100)\n   9 100011000           280 np.uint8(28)\n   9 100011001           281 np.uint8(159)\n   8 10001101            141 np.uint8(191)\n   7 1000111              71 np.uint8(107)\n   8 10010000            144 np.uint8(121)\n   8 10010001            145 np.uint8(115)\n   9 100100100           292 np.uint8(164)\n   9 100100101           293 np.uint8(167)\n   8 10010011            147 np.uint8(195)\n   7 1001010              74 np.uint8(112)\n   8 10010110            150 np.uint8(192)\n   8 10010111            151 np.uint8(38)\n   8 10011000            152 np.uint8(196)\n   8 10011001            153 np.uint8(223)\n   7 1001101              77 np.uint8(76)\n   8 10011100            156 np.uint8(197)\n   9 100111010           314 np.uint8(171)\n   9 100111011           315 np.uint8(168)\n   7 1001111              79 np.uint8(48)\n   7 1010000              80 np.uint8(109)\n   7 1010001              81 np.uint8(44)\n   7 1010010              82 np.uint8(98)\n   8 10100110            166 np.uint8(194)\n   8 10100111            167 np.uint8(198)\n   8 10101000            168 np.uint8(36)\n   9 101010010           338 np.uint8(231)\n  10 1010100110          678 np.uint8(136)\n  10 1010100111          679 np.uint8(139)\n   8 10101010            170 np.uint8(199)\n   8 10101011            171 np.uint8(193)\n   7 1010110              86 np.uint8(54)\n   8 10101110            174 np.uint8(37)\n   9 101011110           350 np.uint8(119)\n  10 1010111110          702 np.uint8(141)\n  10 1010111111          703 np.uint8(143)\n   7 1011000              88 np.uint8(117)\n   7 1011001              89 np.uint8(110)\n   8 10110100            180 np.uint8(200)\n   8 10110101            181 np.uint8(40)\n   9 101101100           364 np.uint8(169)\n   9 101101101           365 np.uint8(239)\n  13 1011011100000      5856 np.uint8(244)\n  16 1011011100001000  46856 np.uint8(253)\n  17 10110111000010010 93714 _EOF\n  17 10110111000010011 93715 np.uint8(252)\n  15 101101110000101   23429 np.uint8(254)\n  14 10110111000011    11715 np.uint8(247)\n  12 101101110001       2929 np.uint8(1)\n  11 10110111001        1465 np.uint8(21)\n  10 1011011101          733 np.uint8(138)\n   9 101101111           367 np.uint8(172)\n   7 1011100              92 np.uint8(52)\n   7 1011101              93 np.uint8(50)\n   8 10111100            188 np.uint8(45)\n  10 1011110100          756 np.uint8(132)\n  10 1011110101          757 np.uint8(133)\n   9 101111011           379 np.uint8(170)\n   8 10111110            190 np.uint8(204)\n   8 10111111            191 np.uint8(42)\n   9 110000000           384 np.uint8(230)\n  11 11000000100        1540 np.uint8(23)\n  12 110000001010       3082 np.uint8(3)\n  12 110000001011       3083 np.uint8(7)\n  10 1100000011          771 np.uint8(140)\n   8 11000001            193 np.uint8(201)\n   7 1100001              97 np.uint8(46)\n   8 11000100            196 np.uint8(202)\n   8 11000101            197 np.uint8(203)\n   7 1100011              99 np.uint8(99)\n   9 110010000           400 np.uint8(237)\n   9 110010001           401 np.uint8(175)\n   8 11001001            201 np.uint8(43)\n   9 110010100           404 np.uint8(176)\n  10 1100101010          810 np.uint8(131)\n  10 1100101011          811 np.uint8(135)\n   9 110010110           406 np.uint8(174)\n   9 110010111           407 np.uint8(229)\n   7 1100110             102 np.uint8(103)\n   7 1100111             103 np.uint8(96)\n   7 1101000             104 np.uint8(47)\n   7 1101001             105 np.uint8(118)\n   8 11010100            212 np.uint8(205)\n  10 1101010100          852 np.uint8(149)\n  10 1101010101          853 np.uint8(240)\n   9 110101011           427 np.uint8(123)\n   9 110101100           428 np.uint8(178)\n   9 110101101           429 np.uint8(173)\n   8 11010111            215 np.uint8(222)\n   6 110110               54 np.uint8(94)\n   9 110111000           440 np.uint8(232)\n  10 1101110010          882 np.uint8(26)\n  10 1101110011          883 np.uint8(142)\n   9 110111010           442 np.uint8(233)\n   9 110111011           443 np.uint8(234)\n   8 11011110            222 np.uint8(221)\n   8 11011111            223 np.uint8(213)\n   7 1110000             112 np.uint8(55)\n  10 1110001000          904 np.uint8(130)\n  10 1110001001          905 np.uint8(137)\n  10 1110001010          906 np.uint8(134)\n  10 1110001011          907 np.uint8(144)\n   8 11100011            227 np.uint8(215)\n   9 111001000           456 np.uint8(180)\n   9 111001001           457 np.uint8(122)\n   8 11100101            229 np.uint8(41)\n   8 11100110            230 np.uint8(207)\n   8 11100111            231 np.uint8(206)\n  10 1110100000          928 np.uint8(147)\n  10 1110100001          929 np.uint8(129)\n   9 111010001           465 np.uint8(177)\n   8 11101001            233 np.uint8(212)\n   8 11101010            234 np.uint8(210)\n   8 11101011            235 np.uint8(209)\n   7 1110110             118 np.uint8(105)\n  10 1110111000          952 np.uint8(27)\n  10 1110111001          953 np.uint8(146)\n   9 111011101           477 np.uint8(228)\n   8 11101111            239 np.uint8(214)\n   8 11110000            240 np.uint8(49)\n   8 11110001            241 np.uint8(208)\n  10 1111001000          968 np.uint8(148)\n  12 111100100100       3876 np.uint8(242)\n  12 111100100101       3877 np.uint8(2)\n  12 111100100110       3878 np.uint8(8)\n  12 111100100111       3879 np.uint8(5)\n   9 111100101           485 np.uint8(31)\n   8 11110011            243 np.uint8(111)\n   8 11110100            244 np.uint8(216)\n   9 111101010           490 np.uint8(125)\n   9 111101011           491 np.uint8(227)\n   9 111101100           492 np.uint8(179)\n  10 1111011010          986 np.uint8(153)\n  11 11110110110        1974 np.uint8(22)\n  11 11110110111        1975 np.uint8(16)\n   8 11110111            247 np.uint8(120)\n   8 11111000            248 np.uint8(218)\n   8 11111001            249 np.uint8(211)\n   9 111110100           500 np.uint8(236)\n  10 1111101010         1002 np.uint8(0)\n  10 1111101011         1003 np.uint8(152)\n   8 11111011            251 np.uint8(68)\n   8 11111100            252 np.uint8(82)\n   8 11111101            253 np.uint8(79)\n   9 111111100           508 np.uint8(181)\n   9 111111101           509 np.uint8(235)\n   8 11111111            255 np.uint8(53)\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nimport io\nfrom contextlib import redirect_stdout\nstd_out = io.StringIO()\ncodec.print_code_table(std_out)\nprint('\\n'.join(std_out.getvalue().split('\\n')[:15]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBits Code              Value Symbol\n   7 0000000               0 np.uint8(97)\n   7 0000001               1 np.uint8(219)\n   9 000001000             8 np.uint8(145)\n   9 000001001             9 np.uint8(151)\n   9 000001010            10 np.uint8(155)\n   9 000001011            11 np.uint8(154)\n   7 0000011               3 np.uint8(108)\n   7 0000100               4 np.uint8(75)\n   7 0000101               5 np.uint8(86)\n   7 0000110               6 np.uint8(217)\n   7 0000111               7 np.uint8(220)\n   7 0001000               8 np.uint8(90)\n   7 0001001               9 np.uint8(64)\n   9 000101000            40 np.uint8(156)\n```\n:::\n:::\n\n\nWe can get the number of bits of the huffman encoding by mapping the intensity values to their corresponding 'codeword', counting the number of bits of each such encoding.\n\n::: {.cell execution_count=7}\n\n::: {.cell-output .cell-output-stdout}\n```\n138.62744140625\n```\n:::\n:::\n\n\nThus, in the above parrot image, we get a pretty modest compression level of 94% (though it is lossless).\n\nOf course, the `greedypermutation` is not a compression algorithm per-se. But it's geometric coverage properties suggest it might be a valid way of approaching the encoding problem. If we arrange the pixel values of the image on the real line and simply run the greedy permutation, starting with black as our starting pint, we get the following set of intensity values:\n\n::: {.cell execution_count=8}\n\n::: {.cell-output .cell-output-stdout}\n```\n[ 58 105  99  99  83  98  96 102  69  76  94  99  96  98 100]\n```\n:::\n:::\n\n\nPredictably, starting with a 0 intensity value (black) as our seed, the furthest pixel away is full intensity (all white), followed by the middle intensity value (128). This makes sense, as the greedy permutation tends to choose extremal values.\n\nWhat happens after is a little surprising. The value should look familiar: each contiguous set of $2^k$ values for $k \\geq 0$ are awfully close to $k$-levels of a bread-first search tree built on top the range $[0, \\dots, 255]$.\n\n```         \n                                  128\n                            /          \\\n                    64              192\n                /   \\           /     \\\n          32     96        160    224\n        /   \\    /  \\     /  \\    /  \\\n     16   48  80  112 144 176 208  240\n```\n\nThis matches intuition: under uniform intensity values, the best way to \"cover\" the range \\[0..255\\] would naturally be to start with the middle value, partition the range into two \\[0..127\\] and \\[129..255\\], then choose the next two points to be the centers of those ranges (in any order). Continuing this process yields a set of pixel values that is guaranteed to halve the minimum distance $d_X(x, S)$ of each intensity value each level of the tree.\n\n::: {.cell execution_count=9}\n\n::: {.cell-output .cell-output-stderr}\n```\nBokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 256), ('y', 254)\n```\n:::\n:::\n\n\nBy converting to black-and-white ($k=2$), we achieve a pleasant compression level comparable to 15% of the original size. But this isn't all: we can *choose* the compression levels by a simple dictionary mapping of codewords. This is sometimes called *progressive compression*.\n\nThus, using the `greedypermutation`, we've turned a classical lossless compression technique into a lossy, progressive compressive technique that recovers the lossless when $k$ is large enough, all without knowing almost anything about compression!\n\n\n\n::: {style=\"display: flex; justify-content: center; align-items: center;\"}\n<iframe src=\"parrot_slider/index.html\" width=\"400px;\" height=\"450px;\" sandbox=\"allow-same-origin allow-scripts allow-forms\" style=\"overflow-y: hidden !important; text-overflow: hidden;\" scrolling=\"no\">\n\n</iframe>\n:::\n\n## Beyond the real line\n\nThe astute read will recognize that, though this little technique is clever, it by not means can compete with the highly advanced, multi-decade in-the-works compressed algorithms (e.g. Lempel-Ziv, WebP). These compression techniques are much more complicated and successful, and industrial. Beyond tiny demonstrations above, there's not too many uses of the `greedypermutation` for 1-d compression.\n\nBut the `greedypermutation` is not limited to the real line. Without changing the underlying algorithm *at all*, we can readily adapt the k-centering approach to higher dimensions. The biggest observation is that works with the metric k-center out-of-the-box:\n\n<!-- TODO: Show the metric k=center objective plot -->\n\n## Generalizing to proximity searching\n\nThe greedy permutation *feels* like a natural, multiscale description of a metric space. Aside from the description given above with black and white pixels, it just seems like one ought to write an algorithm capable of hierarchically decomposing a metric space in a geometrically \"nice\" way for fun and for profit.\n\nOne of my favorite uses of the greedypermutation is the `greedy tree`, an equally simple Ball-tree like construction which provides range searching capability, including radius searches, ANN searching, and KNN.\n\nThis is a recent paper by Don Sheehy that does just this.\n\n## Sometimes the hammer is a good tool\n\nOk, so the greedypermutation can used to solve:\n\n-   Metric k-center\n-   Metric k-cover\n-   Metric k-separation\n-   ANN searching\n-   Ball search\n-   KNN search\n-   Progressive encoding\n\nCan we elegantly extend its use to a\n\ndual tree\n\n",
    "supporting": [
      "landmark_files"
    ],
    "filters": []
  }
}